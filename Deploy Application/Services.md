## Service In OpenShift & Kubernetes

### Services
- Pods are ephemeral by their nature, meaning they die easily. And when a pod dies, its internal IP address dies along with it. And when the pod is being rescheduled and recreated automatically, the pod loses its static IP because the pod IPs are generated by OpenShift dynamically and randomly.
- Hence, other components or applications that are meant to talk to the pod will not be able to talk to the pod because another IP may have been randomly assigned to the pod. So, to avoid this problem, Kubernetes and OpenShift use a component called service.
- The static IP addresses are assigned to a service instead of a pod, and the service sends the request to the pod. So, a service can also act as a load-balancer by load balancing requests and sending them to the appropriate or less busy pods, depending on the request.
- Service gives you access to a pod via an IP address and port. Service, unlike the pod, is not ephemeral in nature, meaning it doesn’t die or go down easily.
- There are two types of services in OpenShift and Kubernetes.(Internal & External)

---

### Internal Service 
- The internal service is used for internal communication within the cluster and doesn’t expose pods or applications to the external or outside world. It is good to use this type of service if you don’t want your applications, especially databases, to be exposed to the outside world.
- The internal service is called the cluster IP. When you create an internal service for a deployment, the cluster IP will be attached to the deployment at the point of creation, and this IP will automatically be generated by OpenShift.
- Let’s say, for example, you created a deployment that has three replicas of a pod. Instead of having to query just one single pod, a cluster IP can be created so that you can direct your request or query to the cluster IP and the cluster IP will forward the request to any of the pods and at the same time do the load balancing among the pods.
- It can forward requests to the less busy pod. This is one of the automated and load-balancing features of Kubernetes and OpenShift service component.
```yaml
oc create deployment nginx-app --image=nginx # Create a deployment

oc expose deployment nginx-app --port=8080 --target-port=80 # Expose the service
# The target port is 80. By default nginx uses port 80. Port 8080 will be exposed via port 80
# Because this is an internal service, if we try using (curl 10.217.5.20:8080), we won’t be able to access the application. Internal service is not exposed to the outside world.

oc describe service nginx-app # To get more information about a service
oc delete service nginx-app #  Delete the service
```

---
### External Service
- External communication is handled by the external service, which exposes ports and applications to the outside world. Of course, your web applications need to be exposed to the outside world so that they can be accessed by the users. So, you can create an external service for this use case.
- There are two types of external services : NodePort & LoadBalancer.

---
### NodePort
- The NodePort external service opens an application to the outside world through the node the pod resides in, and that is why it is called NodePort. So, when a deployment is exposed through a node, one would have to access the application using the node’s IP and a port. Let’s see this in practice.
- You can only access the pod through the node where the pod resides
- Note that I have used the random port that the service has given us (31205). You can always specify a port but for this use case, I’m going to use the random port that has been automatically given to us.
```yaml
oc expose deployment nginx-app --type=NodePort --port=80 # To create the NodePort external service
oc get svc #  Verify
oc get pods -o wide # check with node is pod is running.  
http://192.168.22.201:31205 # check any with any of Node IP address
```

### External Service - LoadBalancer 
- The LoadBalancer external service is mostly used on the cloud, and the cloud service providers are the ones who provide this LoadBalancer IP address. Unlike the NodePort external service, where requests are made through the node where the pod resides, for the LoadBalancer service, the request will be made to the LoadBalancer IP and the LoadBalancer balances the load among the nodes in the cluster and sends requests to the appropriate pods.
- I am using Metallb load balancer, I will create separate page for metallb configuration.
```yaml
oc expose deployment nginx-app --type=LoadBalancer --port=80 # To create the LoadBalancer external service
oc get svc # Get extenal ip
http://192.168.22.162 - Metallb assigned this IP.
```
